{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High-level MXNet Example\n",
    "\n",
    "**In the interest of comparison; a common (custom) data-generator (called yield_mb(X, y, batchsize=64, shuffle=False)) was originally used for all other frameworks - but not for MXNet. I have reproduced the MXNet example using this same generator (wrapping the results in the mx.io.DataBatch class) to test if MXNet is faster than other frameworks just because I was using its own data-generator. This does not appear to be the case. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from common.params import *\n",
    "from common.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS:  linux\n",
      "Python:  3.5.2 |Anaconda custom (64-bit)| (default, Jul  2 2016, 17:53:06) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n",
      "Numpy:  1.13.3\n",
      "MXNet:  0.12.0\n",
      "GPU:  []\n"
     ]
    }
   ],
   "source": [
    "print(\"OS: \", sys.platform)\n",
    "print(\"Python: \", sys.version)\n",
    "print(\"Numpy: \", np.__version__)\n",
    "print(\"MXNet: \", mx.__version__)\n",
    "print(\"GPU: \", get_gpu_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_symbol():\n",
    "    data = mx.symbol.Variable('data')\n",
    "    # size = [(old-size - kernel + 2*padding)/stride]+1\n",
    "    # if kernel = 3, pad with 1 either side\n",
    "    conv1 = mx.symbol.Convolution(data=data, num_filter=50, pad=(1,1), kernel=(3,3))\n",
    "    relu1 = mx.symbol.Activation(data=conv1, act_type=\"relu\")\n",
    "    conv2 = mx.symbol.Convolution(data=relu1, num_filter=50, pad=(1,1), kernel=(3,3))\n",
    "    pool1 = mx.symbol.Pooling(data=conv2, pool_type=\"max\", kernel=(2,2), stride=(2,2))\n",
    "    relu2 = mx.symbol.Activation(data=pool1, act_type=\"relu\")\n",
    "    drop1 = mx.symbol.Dropout(data=relu2, p=0.25)\n",
    "    \n",
    "    conv3 = mx.symbol.Convolution(data=drop1, num_filter=100, pad=(1,1), kernel=(3,3))\n",
    "    relu3 = mx.symbol.Activation(data=conv3, act_type=\"relu\")\n",
    "    conv4 = mx.symbol.Convolution(data=relu3, num_filter=100, pad=(1,1), kernel=(3,3))\n",
    "    pool2 = mx.symbol.Pooling(data=conv4, pool_type=\"max\", kernel=(2,2), stride=(2,2))\n",
    "    relu4 = mx.symbol.Activation(data=pool2, act_type=\"relu\")\n",
    "    drop2 = mx.symbol.Dropout(data=relu4, p=0.25)\n",
    "           \n",
    "    flat1 = mx.symbol.Flatten(data=drop2)\n",
    "    fc1 = mx.symbol.FullyConnected(data=flat1, num_hidden=512)\n",
    "    relu7 = mx.symbol.Activation(data=fc1, act_type=\"relu\")\n",
    "    drop4 = mx.symbol.Dropout(data=relu7, p=0.5)\n",
    "    fc2 = mx.symbol.FullyConnected(data=drop4, num_hidden=N_CLASSES) \n",
    "    \n",
    "    input_y = mx.symbol.Variable('softmax_label')  \n",
    "    m = mx.symbol.SoftmaxOutput(data=fc2, label=input_y, name=\"softmax\")\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_model(m):\n",
    "    if GPU:\n",
    "        ctx = [mx.gpu(0)]\n",
    "    else:\n",
    "        ctx = mx.cpu()\n",
    "    \n",
    "    mod = mx.mod.Module(context=ctx, symbol=m)\n",
    "    mod.bind(data_shapes=[('data', (BATCHSIZE, 3, 32, 32))],\n",
    "             label_shapes=[('softmax_label', (BATCHSIZE,))])\n",
    "\n",
    "    # Glorot-uniform initializer\n",
    "    mod.init_params(initializer=mx.init.Xavier(rnd_type='uniform'))\n",
    "    mod.init_optimizer(optimizer='sgd', \n",
    "                       optimizer_params=(('learning_rate', LR), ('momentum', MOMENTUM), ))\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing train set...\n",
      "Preparing test set...\n",
      "(50000, 3, 32, 32) (10000, 3, 32, 32) (50000,) (10000,)\n",
      "float32 float32 int32 int32\n",
      "CPU times: user 820 ms, sys: 575 ms, total: 1.39 s\n",
      "Wall time: 1.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Data into format for library\n",
    "x_train, x_test, y_train, y_test = cifar_for_library(channel_first=True)\n",
    "\n",
    "# Load data-iterator\n",
    "#train_iter = mx.io.NDArrayIter(x_train, y_train, BATCHSIZE, shuffle=True)\n",
    "# Use custom iterator instead of mx.io.NDArrayIter() for consistency\n",
    "# Wrap as DataBatch class\n",
    "wrapper_db = lambda args: mx.io.DataBatch(data=[mx.nd.array(args[0])], label=[mx.nd.array(args[1])])\n",
    "\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "print(x_train.dtype, x_test.dtype, y_train.dtype, y_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.23137255,  0.16862746,  0.19607843, ...,  0.61960787,\n",
       "           0.59607846,  0.58039218],\n",
       "         [ 0.0627451 ,  0.        ,  0.07058824, ...,  0.48235294,\n",
       "           0.46666667,  0.47843137],\n",
       "         [ 0.09803922,  0.0627451 ,  0.19215687, ...,  0.4627451 ,\n",
       "           0.47058824,  0.42745098],\n",
       "         ..., \n",
       "         [ 0.81568629,  0.78823531,  0.7764706 , ...,  0.627451  ,\n",
       "           0.21960784,  0.20784314],\n",
       "         [ 0.70588237,  0.67843139,  0.72941178, ...,  0.72156864,\n",
       "           0.38039216,  0.32549021],\n",
       "         [ 0.69411767,  0.65882355,  0.7019608 , ...,  0.84705883,\n",
       "           0.59215689,  0.48235294]],\n",
       "\n",
       "        [[ 0.24313726,  0.18039216,  0.1882353 , ...,  0.51764709,\n",
       "           0.49019608,  0.48627451],\n",
       "         [ 0.07843138,  0.        ,  0.03137255, ...,  0.34509805,\n",
       "           0.32549021,  0.34117648],\n",
       "         [ 0.09411765,  0.02745098,  0.10588235, ...,  0.32941177,\n",
       "           0.32941177,  0.28627452],\n",
       "         ..., \n",
       "         [ 0.66666669,  0.60000002,  0.63137257, ...,  0.52156866,\n",
       "           0.12156863,  0.13333334],\n",
       "         [ 0.54509807,  0.48235294,  0.56470591, ...,  0.58039218,\n",
       "           0.24313726,  0.20784314],\n",
       "         [ 0.56470591,  0.50588238,  0.55686277, ...,  0.72156864,\n",
       "           0.4627451 ,  0.36078432]],\n",
       "\n",
       "        [[ 0.24705882,  0.17647059,  0.16862746, ...,  0.42352942,\n",
       "           0.40000001,  0.40392157],\n",
       "         [ 0.07843138,  0.        ,  0.        , ...,  0.21568628,\n",
       "           0.19607843,  0.22352941],\n",
       "         [ 0.08235294,  0.        ,  0.03137255, ...,  0.19607843,\n",
       "           0.19607843,  0.16470589],\n",
       "         ..., \n",
       "         [ 0.3764706 ,  0.13333334,  0.10196079, ...,  0.27450982,\n",
       "           0.02745098,  0.07843138],\n",
       "         [ 0.3764706 ,  0.16470589,  0.11764706, ...,  0.36862746,\n",
       "           0.13333334,  0.13333334],\n",
       "         [ 0.45490196,  0.36862746,  0.34117648, ...,  0.54901963,\n",
       "           0.32941177,  0.28235295]]],\n",
       "\n",
       "\n",
       "       [[[ 0.60392159,  0.49411765,  0.41176471, ...,  0.35686275,\n",
       "           0.34117648,  0.30980393],\n",
       "         [ 0.54901963,  0.56862748,  0.49019608, ...,  0.3764706 ,\n",
       "           0.3019608 ,  0.27843139],\n",
       "         [ 0.54901963,  0.54509807,  0.4509804 , ...,  0.30980393,\n",
       "           0.26666668,  0.26274511],\n",
       "         ..., \n",
       "         [ 0.68627453,  0.61176473,  0.60392159, ...,  0.16470589,\n",
       "           0.23921569,  0.36470589],\n",
       "         [ 0.64705884,  0.61176473,  0.62352943, ...,  0.40392157,\n",
       "           0.48235294,  0.51372552],\n",
       "         [ 0.63921571,  0.61960787,  0.63921571, ...,  0.56078434,\n",
       "           0.56078434,  0.56078434]],\n",
       "\n",
       "        [[ 0.69411767,  0.53725493,  0.40784314, ...,  0.37254903,\n",
       "           0.35294119,  0.31764707],\n",
       "         [ 0.627451  ,  0.60000002,  0.49019608, ...,  0.3882353 ,\n",
       "           0.3137255 ,  0.28627452],\n",
       "         [ 0.60784316,  0.57254905,  0.4509804 , ...,  0.32156864,\n",
       "           0.27450982,  0.27058825],\n",
       "         ..., \n",
       "         [ 0.65490198,  0.60392159,  0.627451  , ...,  0.13333334,\n",
       "           0.20784314,  0.32549021],\n",
       "         [ 0.60392159,  0.59607846,  0.63137257, ...,  0.36470589,\n",
       "           0.44705883,  0.47450981],\n",
       "         [ 0.58039218,  0.58039218,  0.61176473, ...,  0.52156866,\n",
       "           0.52549022,  0.52156866]],\n",
       "\n",
       "        [[ 0.73333335,  0.53333336,  0.37254903, ...,  0.27843139,\n",
       "           0.27843139,  0.27450982],\n",
       "         [ 0.66274512,  0.60392159,  0.4627451 , ...,  0.30588236,\n",
       "           0.24313726,  0.23921569],\n",
       "         [ 0.64313728,  0.58431375,  0.43921569, ...,  0.25098041,\n",
       "           0.21568628,  0.21568628],\n",
       "         ..., \n",
       "         [ 0.65098041,  0.627451  ,  0.66666669, ...,  0.14117648,\n",
       "           0.22352941,  0.35686275],\n",
       "         [ 0.50196081,  0.50980395,  0.55686277, ...,  0.3764706 ,\n",
       "           0.47058824,  0.51372552],\n",
       "         [ 0.47058824,  0.47843137,  0.52156866, ...,  0.54509807,\n",
       "           0.55686277,  0.56470591]]],\n",
       "\n",
       "\n",
       "       [[[ 1.        ,  0.99215686,  0.99215686, ...,  0.99215686,\n",
       "           0.99215686,  0.99215686],\n",
       "         [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "           1.        ,  1.        ],\n",
       "         [ 1.        ,  0.99607843,  0.99607843, ...,  0.99607843,\n",
       "           0.99607843,  0.99607843],\n",
       "         ..., \n",
       "         [ 0.44313726,  0.43529412,  0.41176471, ...,  0.28235295,\n",
       "           0.28235295,  0.28235295],\n",
       "         [ 0.43529412,  0.40784314,  0.3882353 , ...,  0.26666668,\n",
       "           0.27450982,  0.30588236],\n",
       "         [ 0.41568628,  0.3882353 ,  0.37254903, ...,  0.30588236,\n",
       "           0.30980393,  0.3137255 ]],\n",
       "\n",
       "        [[ 1.        ,  0.99215686,  0.99215686, ...,  0.99215686,\n",
       "           0.99215686,  0.99215686],\n",
       "         [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "           1.        ,  1.        ],\n",
       "         [ 1.        ,  0.99607843,  0.99607843, ...,  0.99607843,\n",
       "           0.99607843,  0.99607843],\n",
       "         ..., \n",
       "         [ 0.47058824,  0.4627451 ,  0.43921569, ...,  0.31764707,\n",
       "           0.3137255 ,  0.3137255 ],\n",
       "         [ 0.4627451 ,  0.43529412,  0.41568628, ...,  0.29411766,\n",
       "           0.29803923,  0.32941177],\n",
       "         [ 0.44313726,  0.41568628,  0.40000001, ...,  0.33333334,\n",
       "           0.33333334,  0.33725491]],\n",
       "\n",
       "        [[ 1.        ,  0.99215686,  0.99215686, ...,  0.99215686,\n",
       "           0.99215686,  0.99215686],\n",
       "         [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "           1.        ,  1.        ],\n",
       "         [ 1.        ,  0.99607843,  0.99607843, ...,  0.99607843,\n",
       "           0.99607843,  0.99607843],\n",
       "         ..., \n",
       "         [ 0.43921569,  0.43529412,  0.41568628, ...,  0.3137255 ,\n",
       "           0.30980393,  0.30980393],\n",
       "         [ 0.43137255,  0.40784314,  0.38431373, ...,  0.28627452,\n",
       "           0.29411766,  0.32156864],\n",
       "         [ 0.41176471,  0.38431373,  0.36862746, ...,  0.32549021,\n",
       "           0.32549021,  0.32941177]]],\n",
       "\n",
       "\n",
       "       ..., \n",
       "       [[[ 0.13725491,  0.15686275,  0.16470589, ...,  0.3882353 ,\n",
       "           0.30980393,  0.34901962],\n",
       "         [ 0.22352941,  0.17254902,  0.19607843, ...,  0.61176473,\n",
       "           0.5529412 ,  0.45490196],\n",
       "         [ 0.38431373,  0.25098041,  0.27058825, ...,  0.73725492,\n",
       "           0.46666667,  0.23921569],\n",
       "         ..., \n",
       "         [ 0.28627452,  0.20784314,  0.21176471, ...,  0.06666667,\n",
       "           0.08235294,  0.12941177],\n",
       "         [ 0.23921569,  0.21568628,  0.22352941, ...,  0.09411765,\n",
       "           0.06666667,  0.02745098],\n",
       "         [ 0.17254902,  0.18039216,  0.19215687, ...,  0.10588235,\n",
       "           0.08235294,  0.04705882]],\n",
       "\n",
       "        [[ 0.69803923,  0.6901961 ,  0.6901961 , ...,  0.69411767,\n",
       "           0.57647061,  0.58039218],\n",
       "         [ 0.71372551,  0.72156864,  0.71764708, ...,  0.71372551,\n",
       "           0.69411767,  0.58431375],\n",
       "         [ 0.77254903,  0.74117649,  0.75294119, ...,  0.7647059 ,\n",
       "           0.52941179,  0.30980393],\n",
       "         ..., \n",
       "         [ 0.30980393,  0.24705882,  0.26666668, ...,  0.15686275,\n",
       "           0.14117648,  0.1882353 ],\n",
       "         [ 0.26666668,  0.27450982,  0.30980393, ...,  0.1882353 ,\n",
       "           0.13725491,  0.09019608],\n",
       "         [ 0.21960784,  0.25882354,  0.3019608 , ...,  0.20392157,\n",
       "           0.16862746,  0.12156863]],\n",
       "\n",
       "        [[ 0.92156863,  0.93725491,  0.94509804, ...,  0.85882354,\n",
       "           0.77254903,  0.74117649],\n",
       "         [ 0.91764706,  0.98039216,  0.94117647, ...,  0.78431374,\n",
       "           0.80784315,  0.68627453],\n",
       "         [ 0.92941177,  0.98823529,  0.96078432, ...,  0.80784315,\n",
       "           0.57647061,  0.35294119],\n",
       "         ..., \n",
       "         [ 0.3019608 ,  0.26666668,  0.3137255 , ...,  0.25098041,\n",
       "           0.2       ,  0.19215687],\n",
       "         [ 0.29411766,  0.33725491,  0.40392157, ...,  0.28235295,\n",
       "           0.20784314,  0.1254902 ],\n",
       "         [ 0.28627452,  0.34509805,  0.41176471, ...,  0.3019608 ,\n",
       "           0.25882354,  0.19607843]]],\n",
       "\n",
       "\n",
       "       [[[ 0.74117649,  0.72941178,  0.72549021, ...,  0.68627453,\n",
       "           0.67450982,  0.66274512],\n",
       "         [ 0.76078433,  0.74901962,  0.74509805, ...,  0.67843139,\n",
       "           0.67058825,  0.65490198],\n",
       "         [ 0.81568629,  0.80392158,  0.80000001, ...,  0.68627453,\n",
       "           0.67450982,  0.66274512],\n",
       "         ..., \n",
       "         [ 0.81176472,  0.79607844,  0.79607844, ...,  0.52941179,\n",
       "           0.63529414,  0.65882355],\n",
       "         [ 0.7764706 ,  0.74117649,  0.70588237, ...,  0.69803923,\n",
       "           0.68627453,  0.68627453],\n",
       "         [ 0.7764706 ,  0.74117649,  0.69803923, ...,  0.7647059 ,\n",
       "           0.76862746,  0.7647059 ]],\n",
       "\n",
       "        [[ 0.82745099,  0.81568629,  0.81176472, ...,  0.7647059 ,\n",
       "           0.76078433,  0.76078433],\n",
       "         [ 0.82352942,  0.81176472,  0.80784315, ...,  0.75294119,\n",
       "           0.74901962,  0.74509805],\n",
       "         [ 0.85882354,  0.84705883,  0.84313726, ...,  0.74901962,\n",
       "           0.74509805,  0.74901962],\n",
       "         ..., \n",
       "         [ 0.78039217,  0.7647059 ,  0.76862746, ...,  0.51764709,\n",
       "           0.61960787,  0.63921571],\n",
       "         [ 0.74509805,  0.70980394,  0.67450982, ...,  0.67058825,\n",
       "           0.66274512,  0.66274512],\n",
       "         [ 0.74117649,  0.70980394,  0.66666669, ...,  0.72156864,\n",
       "           0.74117649,  0.74509805]],\n",
       "\n",
       "        [[ 0.94117647,  0.9254902 ,  0.92156863, ...,  0.87843138,\n",
       "           0.87058824,  0.86274511],\n",
       "         [ 0.93725491,  0.9254902 ,  0.92156863, ...,  0.86274511,\n",
       "           0.85490197,  0.84705883],\n",
       "         [ 0.95686275,  0.94117647,  0.93725491, ...,  0.8509804 ,\n",
       "           0.84705883,  0.84313726],\n",
       "         ..., \n",
       "         [ 0.70980394,  0.68627453,  0.67843139, ...,  0.49803922,\n",
       "           0.58823532,  0.59215689],\n",
       "         [ 0.66666669,  0.62352943,  0.57647061, ...,  0.627451  ,\n",
       "           0.61176473,  0.60392159],\n",
       "         [ 0.67843139,  0.63529414,  0.58431375, ...,  0.66274512,\n",
       "           0.67058825,  0.67058825]]],\n",
       "\n",
       "\n",
       "       [[[ 0.89803922,  0.9254902 ,  0.91764706, ...,  0.8509804 ,\n",
       "           0.86666667,  0.87058824],\n",
       "         [ 0.87058824,  0.93725491,  0.9137255 , ...,  0.87450981,\n",
       "           0.89019608,  0.82352942],\n",
       "         [ 0.83529413,  0.91764706,  0.90588236, ...,  0.86274511,\n",
       "           0.86274511,  0.79215688],\n",
       "         ..., \n",
       "         [ 0.58823532,  0.54901963,  0.51764709, ...,  0.87843138,\n",
       "           0.90196079,  0.94509804],\n",
       "         [ 0.53725493,  0.50980395,  0.49019608, ...,  0.70980394,\n",
       "           0.79215688,  0.83137256],\n",
       "         [ 0.47843137,  0.4627451 ,  0.47058824, ...,  0.7019608 ,\n",
       "           0.64313728,  0.63921571]],\n",
       "\n",
       "        [[ 0.89803922,  0.92941177,  0.9254902 , ...,  0.85882354,\n",
       "           0.87450981,  0.87450981],\n",
       "         [ 0.86666667,  0.93725491,  0.91764706, ...,  0.87450981,\n",
       "           0.89411765,  0.82745099],\n",
       "         [ 0.80784315,  0.90980393,  0.9137255 , ...,  0.86274511,\n",
       "           0.85882354,  0.79607844],\n",
       "         ..., \n",
       "         [ 0.56078434,  0.52941179,  0.49803922, ...,  0.87058824,\n",
       "           0.89411765,  0.94509804],\n",
       "         [ 0.51764709,  0.49803922,  0.47450981, ...,  0.70588237,\n",
       "           0.78823531,  0.82745099],\n",
       "         [ 0.46666667,  0.45490196,  0.45490196, ...,  0.69411767,\n",
       "           0.64313728,  0.63921571]],\n",
       "\n",
       "        [[ 0.93725491,  0.96862745,  0.96862745, ...,  0.9137255 ,\n",
       "           0.91764706,  0.9137255 ],\n",
       "         [ 0.89803922,  0.97647059,  0.96470588, ...,  0.9254902 ,\n",
       "           0.93333334,  0.86274511],\n",
       "         [ 0.82745099,  0.93725491,  0.95686275, ...,  0.90980393,\n",
       "           0.90980393,  0.84313726],\n",
       "         ..., \n",
       "         [ 0.52941179,  0.49803922,  0.47058824, ...,  0.85490197,\n",
       "           0.88235295,  0.93333334],\n",
       "         [ 0.49411765,  0.47058824,  0.4509804 , ...,  0.69803923,\n",
       "           0.7764706 ,  0.81176472],\n",
       "         [ 0.44705883,  0.43137255,  0.43529412, ...,  0.67843139,\n",
       "           0.63529414,  0.63137257]]]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.47 ms, sys: 687 Âµs, total: 2.16 ms\n",
      "Wall time: 1.73 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load symbol\n",
    "sym = create_symbol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 739 ms, sys: 778 ms, total: 1.52 s\n",
      "Wall time: 1.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Initialise model\n",
    "model = init_model(sym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Training ('accuracy', 0.34126920614596673)\n",
      "Epoch 1, Training ('accuracy', 0.49851952624839951)\n",
      "Epoch 2, Training ('accuracy', 0.57626440460947503)\n",
      "Epoch 3, Training ('accuracy', 0.63538332266325226)\n",
      "Epoch 4, Training ('accuracy', 0.6732754481434059)\n",
      "Epoch 5, Training ('accuracy', 0.71028729193341866)\n",
      "Epoch 6, Training ('accuracy', 0.73801616517285529)\n",
      "Epoch 7, Training ('accuracy', 0.75780249679897571)\n",
      "Epoch 8, Training ('accuracy', 0.77704865556978231)\n",
      "Epoch 9, Training ('accuracy', 0.79661491677336749)\n",
      "CPU times: user 2min 16s, sys: 27.4 s, total: 2min 43s\n",
      "Wall time: 2min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 145s\n",
    "# Train and log accuracy\n",
    "metric = mx.metric.create('acc')\n",
    "for j in range(EPOCHS):\n",
    "    #train_iter.reset()\n",
    "    metric.reset()\n",
    "    #for batch in train_iter:\n",
    "    for batch in map(wrapper_db, yield_mb(x_train, y_train, BATCHSIZE, shuffle=True)):\n",
    "        model.forward(batch, is_train=True) \n",
    "        model.update_metric(metric, batch.label)\n",
    "        model.backward()              \n",
    "        model.update()\n",
    "    print('Epoch %d, Training %s' % (j, metric.get()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.21 s, sys: 269 ms, total: 1.48 s\n",
      "Wall time: 1.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_guess = model.predict(mx.io.NDArrayIter(x_test, batch_size=BATCHSIZE, shuffle=False))\n",
    "y_guess = np.argmax(y_guess.asnumpy(), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7742\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", 1.*sum(y_guess == y_test)/len(y_guess))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
